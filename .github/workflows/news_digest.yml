name: News Digest Emailer
on:
  schedule:
    # Run every 4 hours
    - cron: '0 */4 * * *'
  workflow_dispatch: # Allow manual triggering

jobs:
  send-digest:
    runs-on: ubuntu-latest
    timeout-minutes: 1000 # Just under 1 hour limit
    
    steps:
    - name: ğŸ“¦ Checkout repository
      uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: ğŸ Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
        cache: 'pip'
    
    - name: ğŸ”§ Install system dependencies
      run: |
        echo "Installing build tools and dependencies..."
        sudo apt-get update
        sudo apt-get install -y build-essential cmake
        echo "âœ… System dependencies installed"
    
    - name: ğŸ“š Install Python dependencies
      run: |
        echo "Upgrading pip..."
        pip3 install --upgrade pip
        echo "Installing Python packages from requirements.txt..."
        pip3 install -r requirements.txt
        echo "âœ… Python dependencies installed"
        echo ""
        echo "Installed packages:"
        pip3 list | grep -E "feedparser|newspaper|llama|huggingface"
    
    - name: ğŸ“ Create directories
      run: |
        echo "Creating models directory..."
        mkdir -p models
        echo "âœ… Directories created"
        ls -la
    
    - name: ğŸ’¾ Check for cached model
      id: cache-model
      uses: actions/cache@v4
      with:
        path: models/mistral-7b-instruct-v0.1.Q4_K_M.gguf
        key: mistral-model-v1
    
    - name: â¬‡ï¸ Download Mistral model
      if: steps.cache-model.outputs.cache-hit != 'true'
      run: |
        echo "ğŸ”„ Cache miss - downloading Mistral 7B model..."
        echo "This will take ~5-10 minutes on first run..."
        python3 -c "
        from huggingface_hub import hf_hub_download
        import os
        print('Starting download from HuggingFace...')
        hf_hub_download(
            repo_id='TheBloke/Mistral-7B-Instruct-v0.1-GGUF',
            filename='mistral-7b-instruct-v0.1.Q4_K_M.gguf',
            local_dir='./models',
            local_dir_use_symlinks=False
        )
        print('âœ… Model downloaded successfully')
        "
      env:
        HF_HUB_DISABLE_PROGRESS_BARS: 1
    
    - name: âœ… Verify model download
      run: |
        echo "Checking model file..."
        if [ ! -f "models/mistral-7b-instruct-v0.1.Q4_K_M.gguf" ]; then
          echo "âŒ Model file not found!"
          exit 1
        fi
        echo "âœ… Model file exists"
        echo "ğŸ“Š Model size: $(ls -lh models/mistral-7b-instruct-v0.1.Q4_K_M.gguf | awk '{print $5}')"
    
    - name: ğŸ“Š Check existing processed URLs
      run: |
        echo "Checking for previously processed articles..."
        if [ -f "processed_urls.json" ]; then
          url_count=$(jq '. | length' processed_urls.json 2>/dev/null || echo "0")
          echo "ğŸ“° Found $url_count previously processed URLs"
          echo "ğŸ” Sample of processed URLs:"
          jq -r '.[:3][]' processed_urls.json 2>/dev/null || echo "None"
        else
          echo "ğŸ“ No processed URLs file found - starting fresh"
        fi
    
    - name: ğŸš€ Run news digest generator
      run: |
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "ğŸš€ Starting News Digest Generation"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo ""
        python3 main.py
        echo ""
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "âœ… News Digest Generation Complete"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    
    - name: ğŸ“ˆ Show generation statistics
      if: always()
      run: |
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "ğŸ“Š GENERATION STATISTICS"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        
        if [ -f "processed_urls.json" ]; then
          url_count=$(jq '. | length' processed_urls.json 2>/dev/null || echo "0")
          echo "ğŸ“° Total processed URLs: $url_count"
          
          # Show newly added URLs (last 10)
          echo ""
          echo "ğŸ†• Recently processed articles:"
          jq -r '.[-10:][]' processed_urls.json 2>/dev/null | head -10 || echo "None"
        else
          echo "âš ï¸ No processed URLs file found"
        fi
        
        echo ""
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

    - name: ğŸ”„ Pull latest changes
      run: |
        echo "Configuring git..."
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action Bot"
        
        echo "Stashing local changes..."
        git stash push -u -m "Temporary stash before pull"
        
        echo "Pulling latest changes from remote..."
        git pull --rebase origin ${{ github.ref_name }}
        
        echo "Reapplying local changes..."
        git stash pop || echo "No stash to pop or conflict - continuing..."
        
        echo "âœ… Repository updated"
      if: always()
    
    - name: ğŸ’¾ Commit processed URLs
      run: |
        echo "Configuring git..."
        git config --local user.email "action@github.com"
        git config --local user.name "GitHub Action Bot"
        
        echo "Staging changes..."
        git add processed_urls.json 2>/dev/null || true
        
        if ! git diff --staged --quiet; then
          url_count=$(jq '. | length' processed_urls.json 2>/dev/null || echo "0")
          echo "Committing changes..."
          git commit -m "ğŸ“§ News digest sent - $url_count total processed URLs [$(date '+%Y-%m-%d %H:%M UTC')]"
          
          echo "Pushing to repository..."
          git push
          echo "âœ… Changes committed and pushed"
        else
          echo "ğŸ“ No changes to commit"
        fi
      if: always()
    
    - name: ğŸ“¦ Upload artifacts
      uses: actions/upload-artifact@v4
      if: always()
      with:
        name: digest-run-${{ github.run_number }}
        path: |
          processed_urls.json
        retention-days: 7
    
    - name: ğŸ“‹ Run summary
      if: always()
      run: |
        echo ""
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "ğŸ“‹ WORKFLOW RUN SUMMARY"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
        echo "ğŸš€ Workflow: ${{ github.workflow }}"
        echo "ğŸ“… Run Number: ${{ github.run_number }}"
        echo "â° Completed: $(date '+%Y-%m-%d %H:%M:%S UTC')"
        echo "ğŸŒ Repository: ${{ github.repository }}"
        echo "ğŸ”— Run URL: https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
        
        if [ -f "processed_urls.json" ]; then
          url_count=$(jq '. | length' processed_urls.json 2>/dev/null || echo "0")
          echo ""
          echo "ğŸ“Š Statistics:"
          echo "   â€¢ Total URLs processed: $url_count"
          echo "   â€¢ Artifact uploaded: digest-run-${{ github.run_number }}"
        fi
        
        echo ""
        echo "ğŸ’¡ Next scheduled run in ~4 hours"
        echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    
    - name: ğŸ§¹ Clean up
      run: |
        echo "Cleaning up large files to save space..."
        rm -rf models/
        echo "âœ… Cleanup complete"
      if: always()